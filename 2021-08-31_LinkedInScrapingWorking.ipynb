{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5229e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "#check google chrome version:chrome://settings/help\n",
    "#source: https://pypi.org/project/chromedriver-binary/92.0.4515.107.0/\n",
    "import chromedriver_binary\n",
    "from time import sleep\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.worthwebscraping.com/how-to-scrape-linkedin-profiles-without-login-using-python/\n",
    "#does not work so far - 2021-08-31\n",
    "#number of seconds to sleep\n",
    "timeSleep = 3\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "sleep(timeSleep)\n",
    "driver.maximize_window()\n",
    "sleep(timeSleep)\n",
    "driver.get(\"https://www.linkedin.com/\")\n",
    "sleep(timeSleep)\n",
    "\n",
    "#save cookies\n",
    "cookies_dict = {}\n",
    "for cookie in driver.get_cookies():\n",
    "    cookies_dict[cookie['name']] = cookie['value']\n",
    "\n",
    "driver.close()\n",
    "\n",
    "sleep(timeSleep)\n",
    "\n",
    "response = requests.get(\"https://www.linkedin.com/company/twitter\",\n",
    "                       cookies = cookies_dict,\n",
    "                        headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',\n",
    "                              'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "                                                   'accept-encoding': 'gzip, deflate, br',\n",
    "                                                   'accept-language': 'en-US,en;q=0.9',\n",
    "                                                   'upgrade-insecure-requests': '1',\n",
    "                                                   'scheme': 'https'})\n",
    "\n",
    "html = response.text\n",
    "\n",
    "HtmlPath = \"linkedIn1.html\"\n",
    "page_fun = open(HtmlPath,'w',encoding='utf-8')\n",
    "page_fun.write(html)\n",
    "page_fun.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0ed6d",
   "metadata": {},
   "source": [
    "### Use package = scrape_linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4e4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "import chromedriver_binary\n",
    "from scrape_linkedin import ProfileScraper\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bac7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a linkedin profile: yeomangoh@yahoo.com, password:08075323\n",
    "#get li_at cookie (need login): https://www.smartwriter.ai/university/how-to-access-your-linkedin-cookie-and-what-exactly-does-a-cookie-do\n",
    "li_at_value = 'AQEDATd4RK4C9QUEAAABe5xdggMAAAF7wGoGA1YAP8VFRmt1hVKulFeHCP-2ztYgJis24Yuq_Bxd7-tMlg8g3NG06cHybRecFh3tJjtGKT2l8s3fWVbctPC2z22jnR0oUFjhuL0-c0fF8FPzku2jlYTx'\n",
    "\n",
    "#git location\n",
    "# C:\\Users\\JiunShyanGoh\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Git\n",
    "\n",
    "#define chromedriver\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "#package location: scrape-linkedin-selenium\n",
    "#https://github.com/austinoboyle/scrape-linkedin-selenium\n",
    "\n",
    "# with ProfileScraper(cookie = li_at_value) as scraper:\n",
    "#     profile = scraper.scrape(user='austinoboyle')\n",
    "# print(profile.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "river = webdriver.Chrome()\n",
    "with ProfileScraper(cookie = li_at_value) as scraper:\n",
    "    profile = scraper.scrape(user='austinoboyle')\n",
    "\n",
    "profileDict = profile.to_dict()\n",
    "resultList = []\n",
    "\n",
    "#personal info\n",
    "colList = ['name', 'phone', 'email', 'company', 'school']\n",
    "resultDict = {}\n",
    "for col in colList:\n",
    "    if col in profileDict['personal_info'].keys():\n",
    "        resultDict[col] = profileDict['personal_info'][col]\n",
    "        \n",
    "#working exp\n",
    "#current job\n",
    "resultDict['current title'] = profileDict['experiences']['jobs'][0]['title']\n",
    "\n",
    "#skill\n",
    "resultDict['skills'] = ','.join([i['name'] for i in profileDict['skills']])\n",
    "\n",
    "pd.DataFrame([resultDict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9685d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get names from organization page\n",
    "url = \"https://healthaxis.com/leadership-team\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')  \n",
    "driver = webdriver.Chrome(options = options)\n",
    "driver.get(url)\n",
    "\n",
    "className = \"wpb_text_column wpb_content_element \"\n",
    "a_Tag = driver.find_elements_by_xpath(\"//div[@class = '%s']/div/p/span/a\"%className)\n",
    "hrefList = [i.get_attribute(\"href\") for i in a_Tag]\n",
    "\n",
    "#clean href \n",
    "nameList = [re.sub(\"-\", \" \", re.search(\".*/(\\w*-\\w*).*/\", i).group(1)) for i in hrefList]\n",
    "userNameList = [re.sub(\" \", \"\", i) for i in nameList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = []\n",
    "failedList = []\n",
    "\n",
    "for userName in userNameList:\n",
    "    \n",
    "    try:\n",
    "        with ProfileScraper(cookie = li_at_value) as scraper:\n",
    "            profile = scraper.scrape(user ='%s'%userName)\n",
    "\n",
    "        profileDict = profile.to_dict()\n",
    "\n",
    "        #personal info\n",
    "        colList = ['name', 'phone', 'email', 'company', 'school']\n",
    "        resultDict = {}\n",
    "        for col in colList:\n",
    "            if col in profileDict['personal_info'].keys():\n",
    "                resultDict[col] = profileDict['personal_info'][col]\n",
    "\n",
    "        #working exp\n",
    "        #current job\n",
    "        resultDict['current title'] = profileDict['experiences']['jobs'][0]['title']\n",
    "\n",
    "        #skill\n",
    "        resultDict['skills'] = ','.join([i['name'] for i in profileDict['skills']])\n",
    "\n",
    "        #store result\n",
    "        resultList.append(resultDict)\n",
    "    \n",
    "    except:\n",
    "        failedList.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff48983",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult = pd.DataFrame(resultList)\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e72cb5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result found\n"
     ]
    }
   ],
   "source": [
    "timeSleep = 3\n",
    "\n",
    "#search and click\n",
    "url = 'https://www.linkedin.com'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')  \n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "# driver.add_cookie({\"name\":\"li_at\", \"value\":li_at_value})\n",
    "\n",
    "email = \"yeomangoh@yahoo.com\"\n",
    "password = \"08075323\"\n",
    "#key in email and password\n",
    "emailBox = driver.find_element_by_xpath(\"//*[@id = 'session_key']\")\n",
    "emailBox.send_keys(email)\n",
    "sleep(timeSleep)\n",
    "passwordBox = driver.find_element_by_xpath(\"//*[@id = 'session_password']\")\n",
    "passwordBox.send_keys(password)\n",
    "\n",
    "#click sign in button\n",
    "sleep(timeSleep)\n",
    "signInButton = driver.find_element_by_xpath(\"//button[@type = 'submit']\")\n",
    "signInButton.click()\n",
    "\n",
    "#click skip button when ask phone number\n",
    "# sleep(timeSleep)\n",
    "# skipButton = driver.find_element_by_xpath(\"//button[@class = 'secondary-action']\")\n",
    "# skipButton.click()\n",
    "\n",
    "#key in text\n",
    "sleep(timeSleep)\n",
    "companyName = \"HealthAxis\"\n",
    "#example where has result\n",
    "name = \"jim Clark\"\n",
    "#example where no result\n",
    "# name = \"michele mahoney\"\n",
    "searchText = name + ' ' + companyName\n",
    "inputBox_xPath = \"//input[@placeholder = 'Search']\"\n",
    "wait = WebDriverWait(driver, 10)\n",
    "auto_element = wait.until(EC.visibility_of_element_located((By.XPATH, inputBox_xPath)))\n",
    "inputBox = driver.find_element_by_xpath(inputBox_xPath)\n",
    "inputBox.send_keys(\"%s\"%searchText)\n",
    "inputBox.send_keys(Keys.RETURN)\n",
    "\n",
    "#click result link\n",
    "sleep(timeSleep)\n",
    "resultLink_xPath = \"//a[@class = 'app-aware-link']\"\n",
    "#here may fail if no results even fuzzy\n",
    "wait = WebDriverWait(driver, 10)\n",
    "auto_element = wait.until(EC.visibility_of_element_located((By.XPATH, resultLink_xPath)))\n",
    "resultLink = driver.find_element_by_xpath(resultLink_xPath)\n",
    "# resultLink.click()\n",
    "\n",
    "#get url from href to pass to scrape_linkedin func:\n",
    "currentUrl = resultLink.get_attribute(\"href\")\n",
    "userName = re.search(\".*/(.*)\\?\", currentUrl).group(1)\n",
    "\n",
    "#example of href where no exact search result\n",
    "#href:https://www.linkedin.com/search/results/all/?keywords=michele%20mahoney%20healthaxis&origin=GLOBAL_SEARCH_HEADER&sid=-5R\n",
    "if re.search(\"results\\/all\", currentUrl):\n",
    "    print(\"No result\")\n",
    "else:\n",
    "    print(\"Result found\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837570e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Jim Clark',\n",
       " 'phone': None,\n",
       " 'email': None,\n",
       " 'company': 'HealthAxis Group',\n",
       " 'school': 'Florida State University - College of Business',\n",
       " 'current title': 'Chief Growth Officer',\n",
       " 'skills': 'Start-ups,Management,Business Development,New Business Development,Strategic Planning,Sales,Mergers & Acquisitions,Leadership,Team Building,Marketing,Salesforce.com,Executive Management,Strategic Partnerships,Healthcare,Sales Management,Entrepreneurship,Marketing Strategy,SaaS,Contract Negotiation,Business Strategy,Product Development,Mobile Devices,Solution Selling,Business Planning,Product Management,CRM,Software as a Service (SaaS),Business Process Improvement,Strategy,Due Diligence'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ProfileScraper(cookie = li_at_value) as scraper:\n",
    "    profile = scraper.scrape(user ='%s'%userName)\n",
    "\n",
    "    profileDict = profile.to_dict()\n",
    "\n",
    "    #personal info\n",
    "    colList = ['name', 'phone', 'email', 'company', 'school']\n",
    "    resultDict = {}\n",
    "    for col in colList:\n",
    "        if col in profileDict['personal_info'].keys():\n",
    "            resultDict[col] = profileDict['personal_info'][col]\n",
    "\n",
    "    #working exp\n",
    "    #current job\n",
    "    resultDict['current title'] = profileDict['experiences']['jobs'][0]['title']\n",
    "\n",
    "    #skill\n",
    "    resultDict['skills'] = ','.join([i['name'] for i in profileDict['skills']])\n",
    "resultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eab707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac7b11ce",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5626ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProfileScraper(cookie = li_at_value, timeout = 10) as scraper:\n",
    "    profile = scraper.scrape(user ='%s'%nameList[1])\n",
    "\n",
    "profileDict = profile.to_dict()\n",
    "\n",
    "#personal info\n",
    "colList = ['name', 'phone', 'email', 'company', 'school']\n",
    "resultDict = {}\n",
    "for col in colList:\n",
    "    if col in profileDict['personal_info'].keys():\n",
    "        resultDict[col] = profileDict['personal_info'][col]\n",
    "\n",
    "#working exp\n",
    "#current job\n",
    "resultDict['current title'] = profileDict['experiences']['jobs'][0]['title']\n",
    "\n",
    "#skill\n",
    "resultDict['skills'] = ','.join([i['name'] for i in profileDict['skills']])\n",
    "\n",
    "#store result\n",
    "resultList.append(resultDict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
